{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "custom_objects = {'mse': mean_squared_error}\n",
    "model = tf.keras.models.load_model('models/feature_extractor_model.keras', custom_objects=custom_objects)\n",
    "rfnew = joblib.load('models/rf_model1.pkl')\n",
    "rf_model = joblib.load('models/rf_model.pkl')\n",
    "scaler = joblib.load('models/scaler.pkl')\n",
    "knn = joblib.load('models/knn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess and predict using rf\n",
    "def preprocess_message(can_message):\n",
    "    \n",
    "    def convert_to_int(x):\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                return int(x, 16)\n",
    "            except ValueError:\n",
    "                return x\n",
    "        return x\n",
    "    \n",
    "    for i in range(8):\n",
    "        can_message[f'data[{i}]'] = convert_to_int(can_message[f'data[{i}]'])\n",
    "    \n",
    "    can_message['can_id'] = convert_to_int(can_message['can_id'])\n",
    "\n",
    "    can_message = pd.DataFrame([can_message])\n",
    "    \n",
    "    can_message = can_message.drop(columns=['ignore'])\n",
    "    can_message = can_message.drop(columns=['dlc'])\n",
    "    preprocessed_message = scaler.transform(can_message)\n",
    "    \n",
    "    return preprocessed_message\n",
    "\n",
    "def predict_can_message(can_message):\n",
    "    preprocessed_message = preprocess_message(can_message)\n",
    "    \n",
    "    features = model.predict(preprocessed_message)\n",
    "    \n",
    "    prediction = rf_model.predict(features)\n",
    "    \n",
    "    return prediction[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "Anomolous:True\n"
     ]
    }
   ],
   "source": [
    "# Example CAN message - predicted using rf\n",
    "can_message = {\n",
    "    'time': 1673043786.214782,\n",
    "    'can_id': 0x3D1,\n",
    "    'ignore': 0x000,\n",
    "    'dlc': 8,\n",
    "    'data[0]': 'FF',\n",
    "    'data[1]': '1F',\n",
    "    'data[2]': '00',\n",
    "    'data[3]': '00',\n",
    "    'data[4]': 'FD',\n",
    "    'data[5]': '00',\n",
    "    'data[6]': '00',\n",
    "    'data[7]': '00'\n",
    "}\n",
    "#1673043786.214782,3D1,FF1F0000FD000000\n",
    "# Predict the message\n",
    "prediction = predict_can_message(can_message)\n",
    "print(f'Anomolous:{bool(prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Anomolous:True\n",
      "\n",
      "next\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Anomolous:True\n"
     ]
    }
   ],
   "source": [
    "a1 = {\n",
    "    'time': 1672281227.925416,\n",
    "    'can_id': 0x1F1,\n",
    "    'ignore': 0x000,\n",
    "    'dlc': 8,\n",
    "    'data[0]': 'AE',\n",
    "    'data[1]': '0E',\n",
    "    'data[2]': '00',\n",
    "    'data[3]': '00',\n",
    "    'data[4]': '08',\n",
    "    'data[5]': '00',\n",
    "    'data[6]': '00',\n",
    "    'data[7]': '7A'\n",
    "}\n",
    "#0.010908,0153,000,8,00,80,10,ff,00,ff,50,de\n",
    "# Predict the message\n",
    "print(f'Anomolous:{bool(predict_can_message(a1))}' )    #rf\n",
    "print(\"\\nnext\\n\")\n",
    "print(f'Anomolous:{bool(predict_can_message2(a1))}' )   #knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Anomalous: True\n"
     ]
    }
   ],
   "source": [
    "#string format\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def preprocess_message(can_message_str):\n",
    "    parts = can_message_str.split(',')\n",
    "    timestamp = float(parts[0])\n",
    "    can_id = parts[1]\n",
    "    data = parts[2]\n",
    "    data_bytes = [data[i:i+2] for i in range(0, len(data), 2)]\n",
    "    while len(data_bytes) < 8:\n",
    "        data_bytes.append('00')\n",
    "    def convert_to_int(x):\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                return int(x, 16)\n",
    "            except ValueError:\n",
    "                return x\n",
    "        return x\n",
    "    for i in range(8):\n",
    "        data_bytes[i] = convert_to_int(data_bytes[i])\n",
    "    can_id = convert_to_int(can_id)\n",
    "    can_message = {\n",
    "        'time': timestamp,\n",
    "        'can_id': can_id,\n",
    "        'data[0]': data_bytes[0],\n",
    "        'data[1]': data_bytes[1],\n",
    "        'data[2]': data_bytes[2],\n",
    "        'data[3]': data_bytes[3],\n",
    "        'data[4]': data_bytes[4],\n",
    "        'data[5]': data_bytes[5],\n",
    "        'data[6]': data_bytes[6],\n",
    "        'data[7]': data_bytes[7]\n",
    "    }\n",
    "    can_message_df = pd.DataFrame([can_message])\n",
    "    preprocessed_message = scaler.transform(can_message_df)\n",
    "    return preprocessed_message\n",
    "def predict_can_message1(can_message_str):\n",
    "    preprocessed_message = preprocess_message(can_message_str)\n",
    "    features = model.predict(preprocessed_message)\n",
    "    prediction = knn.predict(features)\n",
    "    return prediction[0]\n",
    "# CAN message in string format\n",
    "can_message_str = \"1672081958.389626,0F9,0000400000000016\"\n",
    "prediction = predict_can_message1(can_message_str)\n",
    "print(f'Anomalous: {bool(prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "CAN message 1 - Anomalous: False\n",
      "CAN message 2 - Anomalous: False\n",
      "CAN message 3 - Anomalous: False\n",
      "CAN message 4 - Anomalous: True\n",
      "CAN message 5 - Anomalous: True\n",
      "CAN message 6 - Anomalous: True\n",
      "CAN message 7 - Anomalous: False\n",
      "CAN message 8 - Anomalous: True\n"
     ]
    }
   ],
   "source": [
    "#process csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_messageNEW(can_message_str, scaler):\n",
    "    parts = can_message_str.split(',')\n",
    "    timestamp = float(parts[0])\n",
    "    can_id = parts[1]\n",
    "    data = parts[2]\n",
    "\n",
    "    data_bytes = [data[i:i+2] for i in range(0, len(data), 2)]\n",
    "    while len(data_bytes) < 8:\n",
    "        data_bytes.append('00')\n",
    "\n",
    "    def convert_to_int(x):\n",
    "        if isinstance(x, str):\n",
    "            try:\n",
    "                return int(x, 16)\n",
    "            except ValueError:\n",
    "                return x\n",
    "        return x\n",
    "    \n",
    "    for i in range(8):\n",
    "        data_bytes[i] = convert_to_int(data_bytes[i])\n",
    "    \n",
    "    can_id = convert_to_int(can_id)\n",
    "\n",
    "    can_message = {\n",
    "        'time': timestamp,\n",
    "        'can_id': can_id,\n",
    "        'data[0]': data_bytes[0],\n",
    "        'data[1]': data_bytes[1],\n",
    "        'data[2]': data_bytes[2],\n",
    "        'data[3]': data_bytes[3],\n",
    "        'data[4]': data_bytes[4],\n",
    "        'data[5]': data_bytes[5],\n",
    "        'data[6]': data_bytes[6],\n",
    "        'data[7]': data_bytes[7]\n",
    "    }\n",
    "\n",
    "    can_message_df = pd.DataFrame([can_message])\n",
    "    \n",
    "    preprocessed_message = scaler.transform(can_message_df)\n",
    "    \n",
    "    return preprocessed_message\n",
    "\n",
    "def predict_can_messagesNEW(file_path, model, knn, scaler):\n",
    "    with open(file_path, 'r') as file:\n",
    "        can_messages = file.readlines()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for can_message_str in can_messages:\n",
    "        preprocessed_message = preprocess_messageNEW(can_message_str.strip(), scaler)\n",
    "        \n",
    "        features = model.predict(preprocessed_message)\n",
    "        \n",
    "        prediction = knn.predict(features)\n",
    "        predictions.append(bool(prediction[0]))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "file_path = \"data.txt\"\n",
    "\n",
    "predictions = predict_can_messagesNEW(file_path, model, knn, scaler)\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f'CAN message {i+1} - Anomalous: {prediction}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
